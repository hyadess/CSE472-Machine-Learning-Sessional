{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('datasets/telco_churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PRE PROCESSING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the duplicate row count\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df = df.select_dtypes(include=['object'])\n",
    "categorical_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = df.select_dtypes(exclude=['object'])\n",
    "numerical_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name='Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null value count in categorical columns and neumerical columns\n",
    "print(categorical_df.isnull().sum())\n",
    "print(numerical_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in categorical columns with the most frequent value except for the target column\n",
    "for column in categorical_df.columns:\n",
    "    if column != target_column_name:\n",
    "        categorical_df[column]=categorical_df[column].fillna(categorical_df[column].value_counts().index[0])\n",
    "    else:\n",
    "        # drop null rows for target column\n",
    "        categorical_df = categorical_df.dropna(subset=[column])\n",
    "    \n",
    "# replace missing values in numerical columns with the mean except for the target column\n",
    "for column in numerical_df.columns:\n",
    "    if column != target_column_name:\n",
    "        numerical_df[column]=numerical_df[column].fillna(numerical_df[column].mean())\n",
    "    else:\n",
    "        # drop null rows for target column\n",
    "        numerical_df = numerical_df.dropna(subset=[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df.info()\n",
    "numerical_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ENCODING AND SCALING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop customer id column\n",
    "categorical_df = categorical_df.drop(columns=['customerID'])\n",
    "# drop total charges column\n",
    "categorical_df = categorical_df.drop(columns=['TotalCharges'])\n",
    "\n",
    "# total categories for each categorical column\n",
    "for column in categorical_df.columns:\n",
    "    print(f'{column}: {categorical_df[column].nunique()} categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total columns count in categorical_df\n",
    "print(len(categorical_df.columns))\n",
    "categorical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do label encodind for categorical columns if there is only 2 categories, otherwise do one hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# at first, do the label encoding for binary columns\n",
    "le = LabelEncoder()\n",
    "for column in categorical_df.columns:\n",
    "    if categorical_df[column].nunique() == 2:\n",
    "        categorical_df[column] = le.fit_transform(categorical_df[column])\n",
    "\n",
    "# then do one hot encoding for the rest of the columns\n",
    "categorical_df = pd.get_dummies(categorical_df).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(categorical_df.columns))\n",
    "categorical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(numerical_df,categorical_df):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # for the numerical columns\n",
    "    numerical_df = pd.DataFrame(scaler.fit_transform(numerical_df), columns=numerical_df.columns)\n",
    "    # merge them back together\n",
    "    df = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaling(numerical_df,categorical_df):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    # for the numerical columns\n",
    "    numerical_df = pd.DataFrame(scaler.fit_transform(numerical_df), columns=numerical_df.columns)\n",
    "    # merge them back together\n",
    "    df = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_and_encoded_df = minmax_scaling(numerical_df,categorical_df)\n",
    "scaled_and_encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE METRICS IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score\n",
    "def evaluate_model(model_name,y_true, y_pred, y_pred_prob=None,save_scores=True):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)  # how many are correctly classified\n",
    "    sensitivity = tp / (tp + fn) # how many positive cases are correctly classified\n",
    "    specificity = tn / (tn + fp) # how many negative cases are correctly classified\n",
    "    precision = tp / (tp + fp) # how many of the positive predictions are correct\n",
    "    f1 = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "\n",
    "    print(f\"========================================================Model: {model_name}===========================================================\")\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"TN: {tn}, FP: {fp}\")\n",
    "    print(f\"FN: {fn}, TP: {tp}\")\n",
    "    print()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    auroc = None\n",
    "    aupr = None\n",
    "    if y_pred_prob is not None:\n",
    "        auroc = roc_auc_score(y_true, y_pred_prob)\n",
    "        print(f\"AUROC: {auroc:.4f}\")\n",
    "        aupr = average_precision_score(y_true, y_pred_prob)\n",
    "        print(f\"AUPR: {aupr:.4f}\")\n",
    "    \n",
    "    if save_scores==False:\n",
    "        return\n",
    "    # write all the scores in a csv file, if AUROC and AUPR are none, then keep the cells empty\n",
    "    scores = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'Precision': precision,\n",
    "        'F1': f1,\n",
    "        'AUROC': auroc if y_pred_prob is not None else None,\n",
    "        'AUPR': aupr if y_pred_prob is not None else None\n",
    "    }\n",
    "\n",
    "\n",
    "    #write in csv, if the file does not exist, then create it and write the header\n",
    "    import os\n",
    "    if not os.path.exists('scores.csv'):\n",
    "        scores_df = pd.DataFrame([scores])\n",
    "        scores_df.to_csv('scores.csv', index=False)\n",
    "    else:\n",
    "        scores_df = pd.read_csv('scores.csv')\n",
    "        scores_df = pd.concat([scores_df, pd.DataFrame([scores])], ignore_index=True)\n",
    "        \n",
    "        scores_df.to_csv('scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about roc and pr curve-->\n",
    "# the model gives the probability of the positive class for each sample.\n",
    "# we define a threshold to convert these probabilities to class labels. ( normally 0.5)\n",
    "# we can change the threshold to get different confusion matrix values\n",
    "# but we can't change the threshold to get different roc and pr curve values\n",
    "# because roc and pr curve are plotted by changing the threshold from 0 to 1\n",
    "# roc curve is plotted with TPR = TP / (TP + FN) vs FPR = FP / (FP + TN) for every threshold value\n",
    "# pr curve is plotted with precision = TP / (TP + FP) and recall = TP / (TP + FN) for every threshold value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Logistic regression model\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000, regularization=None, strength=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.regularization = regularization\n",
    "        self.regularization_strength = strength\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.theta = np.zeros(X.shape[1]) # theta is a vector of zeros with the same size as the number of features\n",
    "        self.bias = 0 # bias is initialized to 0\n",
    "        m = X.shape[0] # number of samples\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            linear_model = np.dot(X, self.theta) + self.bias # z = X.theta + b\n",
    "            predictions = sigmoid(linear_model) # a = sigmoid(z)\n",
    "            \n",
    "            dw = (1 / m) * np.dot(X.T, (predictions - y)) # X.T is the transpose of X. And np.dot returns an array with the size of the number of features\n",
    "            db = (1 / m) * np.sum(predictions - y)\n",
    "\n",
    "            if self.regularization == 'l1':\n",
    "                dw += (self.regularization_strength / m) * np.sign(self.theta) # derivative of L1 regularization = the sign of theta * the regularization strength * 1/m\n",
    "            elif self.regularization == 'l2':\n",
    "                dw += (self.regularization_strength / m) * self.theta # derivative of L2 regularization = theta  * the regularization strength * 1/m\n",
    "            \n",
    "            self.theta -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.theta) + self.bias\n",
    "        predictions = sigmoid(linear_model)\n",
    "        return [1 if i > 0.5 else 0 for i in predictions]\n",
    "    # return prediction probabilities\n",
    "    def predict_prob(self, X):\n",
    "        linear_model = np.dot(X, self.theta) + self.bias\n",
    "        predictions = sigmoid(linear_model)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def bagging_models(X_train, y_train, n_models=9,regularization=None,strength=0.01,saving_scores=True):\n",
    "    base_model_predictions = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        # Bootstrap sampling of training data\n",
    "        X_resampled, y_resampled = resample(X_train, y_train)\n",
    "        \n",
    "        model = MyLogisticRegression(regularization=regularization, strength=strength)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        \n",
    "        y_pred = model.predict(X_train)  # an np array with length of number of samples\n",
    "        y_pred_prob = model.predict_prob(X_train)\n",
    "\n",
    "        evaluate_model(f'LR_Model_{i}',y_train, y_pred, y_pred_prob,save_scores=saving_scores)\n",
    "        \n",
    "        base_model_predictions.append(y_pred) # 2d np array with shape (n_models, n_samples)\n",
    "    \n",
    "    \n",
    "    return np.array(base_model_predictions).T # 2d np array with shape (n_samples, n_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the meta learner model\n",
    "def stack_ensembling(X_train, y_train, n_models=9, regularization=None, strength=0.01, saving_scores=True):\n",
    "    \n",
    "    X_meta_train = bagging_models(X_train, y_train, n_models=n_models, regularization=regularization, strength=strength, saving_scores=saving_scores)\n",
    "    # for meta learner, the predictions of the base models are the features\n",
    "    print(\"done\")\n",
    "    meta_learner = MyLogisticRegression(regularization=regularization, strength=strength)\n",
    "    meta_learner.fit(X_meta_train, y_train)\n",
    "    return meta_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_stack_ensembling(scaled_and_encoded_df, target_column_name, n_models=9, regularization=None, strength=0.01):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = scaled_and_encoded_df.drop(columns=[target_column_name])\n",
    "    y = scaled_and_encoded_df[target_column_name]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    meta_learner = stack_ensembling(X_train, y_train, n_models=n_models, regularization=regularization, strength=strength, saving_scores=False)\n",
    "    X_meta_test = bagging_models(X_test, y_test, n_models=n_models, regularization=regularization, strength=strength, saving_scores=True)\n",
    "\n",
    "    # return true value, the predicted values, and the probabilities\n",
    "    y_pred = meta_learner.predict(X_meta_test)\n",
    "    y_pred_prob = meta_learner.predict_prob(X_meta_test)\n",
    "    return y_test, y_pred, y_pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with stack ensembling\n",
    "y_test,y_pred, y_pred_prob = predict_with_stack_ensembling(scaled_and_encoded_df, target_column_name, n_models=9)\n",
    "\n",
    "# get the accuracy score\n",
    "\n",
    "evaluate_model('StackEnsemble',y_test, y_pred, y_pred_prob,save_scores=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
